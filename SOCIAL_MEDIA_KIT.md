# ğŸ“± Ollama Phone Chat - Social Media Kit (v0.0.4)

## ğŸ’¼ LinkedIn Post

**Headline:** Secure, Local AI on Your Phone â€“ Introducing Ollama Phone Chat v0.0.4 ğŸš€

I'm excited to share the initial public release of **Ollama Phone Chat**, a mobile-first bridge that lets you interact with your local LLMs (like Llama 3 or DeepSeek-R1) directly from your smartphone.

**Why use it?**
Most mobile AI apps rely on the cloud. This project keeps 100% of your data on your local network. It turns your desktop into a powerhouse server and your phone into a premium, private client.

**New in v0.0.4:**
ğŸ”’ **Enterprise-Grade Security**: Now features Transparent Data Encryption (AES-256) and a secure login overlay.
ğŸ§  **"Thinking" Support**: Native visualization for reasoning models. Watch the model's thought process unfold.
ğŸ“± **Mobile-First UI**: A polished, responsive experience designed specifically for thumbs.

Completely Open Source and Local-First.
Check it out on GitHub: [Link to Repo]

#LocalLLM #Ollama #DeepSeek #OpenSource #AI #Privacy #WebDevelopment

---

## ğŸ¤– Reddit Post (r/LocalLLaMA, r/SelfHosted)

**Title:** I built a mobile bridge for Ollama so I could chat with DeepSeek-R1 from my couch (Encrypted + "Thinking" Support)

Hey everyone,

I wanted a way to use my local Ollama models on my phone without exposing them to the web or dealing with clunky UIs. So I built **Ollama Phone Chat**.

Itâ€™s a zero-config Node.js app. You run it on your PC, scan a QR code, and boomâ€”you have a full chat interface on your phone.

**Key Features in v0.0.4:**
*   **DeepSeek Support**: It actually renders the `<think>` tags as a collapsible "Thinking..." block so you can see the reasoning process without it cluttering the chat.
*   **Encrypted History**: If you set a password, it encrypts your local SQLite DB with AES-256.
*   **Mobile-First**: Smooth animations, haptic-feeling UI, dark mode.

It's completely open-source. I just pushed v0.0.4 today. Would love to hear what you think!

[Link to GitHub Repo]

---

## ğŸ¦ X (Twitter) Post

Run local LLMs on your phone with ZERO config. ğŸ“±ğŸ¤–

Introducing **Ollama Phone Chat v0.0.4**:
âœ¨ Chat with Llama 3, DeepSeek, & more over local Wi-Fi.
ğŸ§  Native "Thinking" block support for reasoning models.
ğŸ”’ AES-256 Encrypted Chat History.
ğŸš« No Cloud. 100% Private.

Just `npm start` and scan the QR code.

Grab it here: [Link to Repo]

#Ollama #LocalAI #DeepSeek #OpenSource #DevCommunity
